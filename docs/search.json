[
  {
    "objectID": "docs/lab6.html",
    "href": "docs/lab6.html",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "Code\n##opening libraries \nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(tidymodels)\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.3.0\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.8     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.3.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\n\nCode\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\nCode\nlibrary(baguette)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(dplyr)"
  },
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "Lab Set Up\n\n\nCode\n##opening libraries \nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(tidymodels)\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\n\nCode\nlibrary(powerjoin)\n\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\n\nCode\nlibrary(glue)\nlibrary(vip)\n\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\nCode\nlibrary(baguette)\n\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n\n\n\nData Download\n\n\nCode\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\n\n\n\nGetting the documentation PDF\n\n\nCode\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 'data/camels_attributes_v2.0.pdf')\n\n\nWarning in\ndownload.file(\"https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf\",\n: URL https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf:\ncannot open destfile 'data/camels_attributes_v2.0.pdf', reason 'No such file or\ndirectory'\n\n\nWarning in\ndownload.file(\"https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf\",\n: download had nonzero exit status\n\n\n\n\nGetting Basin characteristics"
  },
  {
    "objectID": "docs/lab6.html#build-your-own",
    "href": "docs/lab6.html#build-your-own",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Build Your Own",
    "text": "Build Your Own\n\nData Splitting\n\n\nCode\nset.seed(\"82304\")\n\ncamels_split &lt;- initial_split(camels, prop = 0.75)\n\ncamels_train &lt;- training(camels_split)\n\ncamels_test &lt;- testing(camels_split)\n\ncamels_resample &lt;- vfold_cv(camels_train, v = 10)\n\n\n\n\nRecipe\nThe formula I chose was logQmean ~ high_prec_freq + soil_porosity. I chose this formula because q_mean is looking at mean discharge. High precipitation frequency might be able to predict mean discharge as more frequent high precipitation events may increase the mean discharge. I chose to also look at soil porosity since this effects runoff. Low soil porosity and frequent high precipitation days may indicate high runoff which would likely increase mean discharge.\n\n\nCode\n# First I want to check the relationship between high_q_freq, baseflow_index, and q_mean\n\nggplot(camels, aes(x = high_prec_freq, y = soil_porosity)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = logQmean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"High Precipitation Frequency vs Soil Porosity vs Log Mean Discharge\", \n       x = \"High Precipitation Frequency\", \n       y = \"Soil Porosity\",\n       color = \"Log Mean Discharge\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\n# from the ggplot, there doesn't seem to be a strong linear relationship between \nnew_recipe &lt;- recipe(logQmean ~ high_prec_freq + soil_porosity, data = camels_train) %&gt;%\n  # add interaction btwn high prec freq and soil porosity\n  step_interact(terms = ~ high_prec_freq:soil_porosity) %&gt;%\n  # drop nas\n  step_naomit(all_predictors(), all_outcomes())\n\n\n\n\nDefine 3 Models\n\n\nCode\nnew_rand_forest &lt;- rand_forest()%&gt;%\n  set_engine(\"ranger\")%&gt;%\n  set_mode(\"regression\")\n\nnew_boost_model &lt;- \n  boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n  \nnew_nnet_model &lt;-\n  bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\n\n\n\nWorkflow set()\n\n\nCode\nnew_wf &lt;- workflow_set(list(new_recipe), list(new_rand_forest, new_boost_model, new_nnet_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_resample) \n\n\n\n\nEvaluation\n\n\nCode\nautoplot(new_wf)\n\n\n\n\n\n\n\n\n\nCode\nrank_results(new_wf, rank_metric = \"rsq\", select_best = TRUE)\n\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.864  0.0347    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.450  0.0316    10 recipe       rand…     1\n3 recipe_bag_mlp    Prepro… rmse    0.870  0.0389    10 recipe       bag_…     2\n4 recipe_bag_mlp    Prepro… rsq     0.441  0.0350    10 recipe       bag_…     2\n5 recipe_boost_tree Prepro… rmse    0.908  0.0239    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.407  0.0315    10 recipe       boos…     3\n\n\nOf these models, it appears the best fit is the random forest model, as it has the lowest RMSE and highest RSQ. However, it is important to note that all three models have low RSQ values, indicating that the models are unsuccessful (an RSQ of &gt; 0.9 would indicate a successful model). While the random forest model has a marginally higher RSQ than the other models, it is only 0.45, indicating a poor fit.\n\n\nExtract and Evaluate\n\n\nCode\nnew_rf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(new_recipe) %&gt;%\n  # Add the model\n  add_model(new_rand_forest) %&gt;%\n  # Fit the model\n  fit(data = camels_train) \n\nrand_forest_data &lt;- augment(new_rf_wf, new_data = camels_test)\n\ncompare &lt;- full_join(rand_forest_data, camels, by = \"gauge_id\") |&gt;\n  mutate(logQmean = log(q_mean.x))\n\nggplot(compare, aes(x = .pred, y = logQmean)) +\n  geom_point(aes(color = logQmean))+\n  geom_abline(slope = 1, intercept = 0, color = \"red\")\n\n\nWarning: Removed 503 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThere seems to be some points clustered around the 1:1 line indicating that there are some accurate predictions from the random forest model of the actual observed values for logQmean. However, points are somewhat scattered suggesting many of the predicted values differ from actual values. The negative values are confusing considering this data is discharge data and we would not expect to see negative discharge unless we were comparing to previous discharge values."
  }
]